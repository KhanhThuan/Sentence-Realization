train:499 sentences
=> Optimizing Lambda: [0.1,0.2,-0.1]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10029 / 12293 = 0.8158
BLEU_precision(3) = 8494 / 11768 = 0.7218
BLEU_precision(4) = 7190 / 11244 = 0.6395
BLEU_precision = 0.7833
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7833

 
	========================================================
train:499 sentences
=> Optimizing Lambda: [0.1,0.2,-0.1]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10029 / 12293 = 0.8158
BLEU_precision(3) = 8494 / 11768 = 0.7218
BLEU_precision(4) = 7190 / 11244 = 0.6395
BLEU_precision = 0.7833
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7833

 
	========================================================
train:499 sentences
=> Optimizing Lambda: [-0.05,-0.6577977590753961,0.46016061237234096]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9317 / 12293 = 0.7579
BLEU_precision(3) = 7376 / 11768 = 0.6268
BLEU_precision(4) = 5746 / 11244 = 0.5110
BLEU_precision = 0.7019
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7019

 
	========================================================
train:499 sentences
=> Optimizing Lambda: [-0.05,-0.6577977590753961,0.46016061237234096]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9317 / 12293 = 0.7579
BLEU_precision(3) = 7376 / 11768 = 0.6268
BLEU_precision(4) = 5746 / 11244 = 0.5110
BLEU_precision = 0.7019
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7019

 
	========================================================
train:499 sentences
=> Optimizing Lambda: [-0.21052430917292875,0.981831267676273,8693020.75161818]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9327 / 12293 = 0.7587
BLEU_precision(3) = 7382 / 11768 = 0.6273
BLEU_precision(4) = 5759 / 11244 = 0.5122
BLEU_precision = 0.7027
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7027

 
	========================================================
train:499 sentences
=> Optimizing Lambda: [-0.21052430917292875,0.981831267676273,8693020.75161818]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9327 / 12293 = 0.7587
BLEU_precision(3) = 7382 / 11768 = 0.6273
BLEU_precision(4) = 5759 / 11244 = 0.5122
BLEU_precision = 0.7027
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7027

 
	========================================================
train:100 sentences
=> Optimizing Lambda: [3300.6444589634457,7929434.30054603,-27264.54821554008]
test:50 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 1429 / 1429 = 1.0000
BLEU_precision(2) = 1024 / 1379 = 0.7426
BLEU_precision(3) = 789 / 1329 = 0.5937
BLEU_precision(4) = 602 / 1279 = 0.4707
BLEU_precision = 0.6749
Length of candidate corpus = 1429
Effective length of reference corpus = 1429
BLEU_BP = 1.0000
  => BLEU = 0.6749

 
	========================================================
train:100 sentences
=> Optimizing Lambda: [3300.6444589634457,7929434.30054603,-27264.54821554008]
test:50 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 1429 / 1429 = 1.0000
BLEU_precision(2) = 1024 / 1379 = 0.7426
BLEU_precision(3) = 789 / 1329 = 0.5937
BLEU_precision(4) = 602 / 1279 = 0.4707
BLEU_precision = 0.6749
Length of candidate corpus = 1429
Effective length of reference corpus = 1429
BLEU_BP = 1.0000
  => BLEU = 0.6749

 
	========================================================
train:500 sentences
=> Optimizing Lambda: [-1226.468439333556,3665.2324727412088,3143.6345487968056]
test:400 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 10179 / 10179 = 1.0000
BLEU_precision(2) = 6771 / 9779 = 0.6924
BLEU_precision(3) = 4973 / 9379 = 0.5302
BLEU_precision(4) = 3485 / 8980 = 0.3881
BLEU_precision = 0.6144
Length of candidate corpus = 10179
Effective length of reference corpus = 10179
BLEU_BP = 1.0000
  => BLEU = 0.6144

 
	========================================================
train:500 sentences
=> Optimizing Lambda: [-0.13287646509006532,-0.6577977590753961,-0.44235450692001854]
test:400 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 10179 / 10179 = 1.0000
BLEU_precision(2) = 7458 / 9779 = 0.7627
BLEU_precision(3) = 5891 / 9379 = 0.6281
BLEU_precision(4) = 4595 / 8980 = 0.5117
BLEU_precision = 0.7036
Length of candidate corpus = 10179
Effective length of reference corpus = 10179
BLEU_BP = 1.0000
  => BLEU = 0.7036

 
	========================================================
train:1000 sentences
=> Optimizing Lambda: [-0.050006688033419906,-0.6577977590753961,-4.452980779849642E-5]
test:400 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 8414 / 8414 = 1.0000
BLEU_precision(2) = 5943 / 8014 = 0.7416
BLEU_precision(3) = 4535 / 7615 = 0.5955
BLEU_precision(4) = 3405 / 7218 = 0.4717
BLEU_precision = 0.6756
Length of candidate corpus = 8414
Effective length of reference corpus = 8414
BLEU_BP = 1.0000
  => BLEU = 0.6756

 
	========================================================
train:1000 sentences
=> Optimizing Lambda: [-0.05,-0.5713556223455967,0.05]
test:400 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 8414 / 8414 = 1.0000
BLEU_precision(2) = 5916 / 8014 = 0.7382
BLEU_precision(3) = 4527 / 7615 = 0.5945
BLEU_precision(4) = 3412 / 7218 = 0.4727
BLEU_precision = 0.6749
Length of candidate corpus = 8414
Effective length of reference corpus = 8414
BLEU_BP = 1.0000
  => BLEU = 0.6749

 
	========================================================
train:200 sentences
=> Optimizing Lambda: [0.05,0.8593774528720801,-0.055347593582887704]
test:200 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 5752 / 5752 = 1.0000
BLEU_precision(2) = 4202 / 5552 = 0.7568
BLEU_precision(3) = 3301 / 5352 = 0.6168
BLEU_precision(4) = 2534 / 5152 = 0.4918
BLEU_precision = 0.6922
Length of candidate corpus = 5752
Effective length of reference corpus = 5752
BLEU_BP = 1.0000
  => BLEU = 0.6922

 
	========================================================
train:200 sentences
=> Optimizing Lambda: [0.05,0.8593774528720801,-0.055347593582887704]
test:200 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 5752 / 5752 = 1.0000
BLEU_precision(2) = 4202 / 5552 = 0.7568
BLEU_precision(3) = 3301 / 5352 = 0.6168
BLEU_precision(4) = 2534 / 5152 = 0.4918
BLEU_precision = 0.6922
Length of candidate corpus = 5752
Effective length of reference corpus = 5752
BLEU_BP = 1.0000
  => BLEU = 0.6922

 
	========================================================
train:10 sentences
=> Optimizing Lambda: [-0.05,-0.05,-0.1]
test:2 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 42 / 42 = 1.0000
BLEU_precision(2) = 32 / 40 = 0.8000
BLEU_precision(3) = 25 / 38 = 0.6579
BLEU_precision(4) = 19 / 36 = 0.5278
BLEU_precision = 0.7260
Length of candidate corpus = 42
Effective length of reference corpus = 42
BLEU_BP = 1.0000
  => BLEU = 0.7260

 
	========================================================
train:10 sentences
=> Optimizing Lambda: [-3.341598746054889E-17,-0.05,0.04999999620769821]
test:2 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 42 / 42 = 1.0000
BLEU_precision(2) = 32 / 40 = 0.8000
BLEU_precision(3) = 25 / 38 = 0.6579
BLEU_precision(4) = 19 / 36 = 0.5278
BLEU_precision = 0.7260
Length of candidate corpus = 42
Effective length of reference corpus = 42
BLEU_BP = 1.0000
  => BLEU = 0.7260

 
	========================================================
train:10 sentences
=> Optimizing Lambda: [-3.341598746054889E-17,-0.05,0.04999999620769821]
test:2 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 42 / 42 = 1.0000
BLEU_precision(2) = 32 / 40 = 0.8000
BLEU_precision(3) = 25 / 38 = 0.6579
BLEU_precision(4) = 19 / 36 = 0.5278
BLEU_precision = 0.7260
Length of candidate corpus = 42
Effective length of reference corpus = 42
BLEU_BP = 1.0000
  => BLEU = 0.7260

 
	========================================================
train:10 sentences
=> Optimizing Lambda: [-3.341598746054889E-17,-0.05,0.04999999620769821]
test:2 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 42 / 42 = 1.0000
BLEU_precision(2) = 32 / 40 = 0.8000
BLEU_precision(3) = 25 / 38 = 0.6579
BLEU_precision(4) = 19 / 36 = 0.5278
BLEU_precision = 0.7260
Length of candidate corpus = 42
Effective length of reference corpus = 42
BLEU_BP = 1.0000
  => BLEU = 0.7260

 
	========================================================
train:10 sentences
=> Optimizing Lambda: [-3.341598746054889E-17,-0.05,0.04999999620769821]
test:2 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 42 / 42 = 1.0000
BLEU_precision(2) = 33 / 40 = 0.8250
BLEU_precision(3) = 28 / 38 = 0.7368
BLEU_precision(4) = 24 / 36 = 0.6667
BLEU_precision = 0.7979
Length of candidate corpus = 42
Effective length of reference corpus = 42
BLEU_BP = 1.0000
  => BLEU = 0.7979

 
	========================================================
train:200 sentences
=> Optimizing Lambda: [0.05,7.628951924593067E-4,-5.029322692678147E11]
test:200 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 5752 / 5752 = 1.0000
BLEU_precision(2) = 4288 / 5552 = 0.7723
BLEU_precision(3) = 3420 / 5352 = 0.6390
BLEU_precision(4) = 2666 / 5152 = 0.5175
BLEU_precision = 0.7109
Length of candidate corpus = 5752
Effective length of reference corpus = 5752
BLEU_BP = 1.0000
  => BLEU = 0.7109

 
	========================================================
train:200 sentences
=> Optimizing Lambda: [-12.464347710289957,-0.6577977590753961,-5.469906598431563E15]
test:200 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 5752 / 5752 = 1.0000
BLEU_precision(2) = 3945 / 5552 = 0.7106
BLEU_precision(3) = 2871 / 5352 = 0.5364
BLEU_precision(4) = 1975 / 5152 = 0.3833
BLEU_precision = 0.6183
Length of candidate corpus = 5752
Effective length of reference corpus = 5752
BLEU_BP = 1.0000
  => BLEU = 0.6183

 
	========================================================
train:200 sentences
=> Optimizing Lambda: [-12.464347710289957,-0.6577977590753961,-5.469906598431563E15]
test:200 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 5752 / 5752 = 1.0000
BLEU_precision(2) = 3945 / 5552 = 0.7106
BLEU_precision(3) = 2871 / 5352 = 0.5364
BLEU_precision(4) = 1975 / 5152 = 0.3833
BLEU_precision = 0.6183
Length of candidate corpus = 5752
Effective length of reference corpus = 5752
BLEU_BP = 1.0000
  => BLEU = 0.6183

 
	========================================================
train:200 sentences
=> Optimizing Lambda: [-12.464347710289957,-0.6577977590753961,-5.469906598431563E15]
test:200 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 5752 / 5752 = 1.0000
BLEU_precision(2) = 3945 / 5552 = 0.7106
BLEU_precision(3) = 2871 / 5352 = 0.5364
BLEU_precision(4) = 1975 / 5152 = 0.3833
BLEU_precision = 0.6183
Length of candidate corpus = 5752
Effective length of reference corpus = 5752
BLEU_BP = 1.0000
  => BLEU = 0.6183

 
	========================================================
train:200 sentences
=> Optimizing Lambda: [0.05,-0.2974935383022126,0.175]
test:200 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 5752 / 5752 = 1.0000
BLEU_precision(2) = 4406 / 5552 = 0.7936
BLEU_precision(3) = 3653 / 5352 = 0.6825
BLEU_precision(4) = 2995 / 5152 = 0.5813
BLEU_precision = 0.7491
Length of candidate corpus = 5752
Effective length of reference corpus = 5752
BLEU_BP = 1.0000
  => BLEU = 0.7491

 
	========================================================
train:200 sentences
=> Optimizing Lambda: [-19.864606864529904,4.153308154484208E15,-1.1706222002748015]
test:200 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 5752 / 5752 = 1.0000
BLEU_precision(2) = 4296 / 5552 = 0.7738
BLEU_precision(3) = 3428 / 5352 = 0.6405
BLEU_precision(4) = 2688 / 5152 = 0.5217
BLEU_precision = 0.7131
Length of candidate corpus = 5752
Effective length of reference corpus = 5752
BLEU_BP = 1.0000
  => BLEU = 0.7131

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
=> Optimizing Lambda: [-1.0529148517942134E-9,-0.6577977590753961,0.46016061237234096]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9570 / 12293 = 0.7785
BLEU_precision(3) = 7772 / 11768 = 0.6604
BLEU_precision(4) = 6261 / 11244 = 0.5568
BLEU_precision = 0.7315
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7315

 
	========================================================
train:200 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
=> Optimizing Lambda: [0.04699954805175292,2.750969892442886E12,4.3698727375931856E14]
test:200 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 5752 / 5752 = 1.0000
BLEU_precision(2) = 4570 / 5552 = 0.8231
BLEU_precision(3) = 3897 / 5352 = 0.7281
BLEU_precision(4) = 3308 / 5152 = 0.6421
BLEU_precision = 0.7876
Length of candidate corpus = 5752
Effective length of reference corpus = 5752
BLEU_BP = 1.0000
  => BLEU = 0.7876

 
	========================================================
train:200 sentences
NGRAM SMOOTH Method: Add one Smoothing
=> Optimizing Lambda: [-158.13593414132416,2.0577786611560332E13,6.786210296750555E14]
test:200 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 5752 / 5752 = 1.0000
BLEU_precision(2) = 4595 / 5552 = 0.8276
BLEU_precision(3) = 3940 / 5352 = 0.7362
BLEU_precision(4) = 3356 / 5152 = 0.6514
BLEU_precision = 0.7937
Length of candidate corpus = 5752
Effective length of reference corpus = 5752
BLEU_BP = 1.0000
  => BLEU = 0.7937

 
	========================================================
train:200 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
=> Optimizing Lambda: [-70.69801203219343,4.6898228242528456E16,-2.7457749172640007]
test:200 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 5752 / 5752 = 1.0000
BLEU_precision(2) = 4323 / 5552 = 0.7786
BLEU_precision(3) = 3499 / 5352 = 0.6538
BLEU_precision(4) = 2796 / 5152 = 0.5427
BLEU_precision = 0.7250
Length of candidate corpus = 5752
Effective length of reference corpus = 5752
BLEU_BP = 1.0000
  => BLEU = 0.7250

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
=> Optimizing Lambda: [-0.6109403606749327,1.8368550528726916E14,3.97771370237394E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10211 / 12293 = 0.8306
BLEU_precision(3) = 8761 / 11768 = 0.7445
BLEU_precision(4) = 7497 / 11244 = 0.6668
BLEU_precision = 0.8013
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8013

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
=> Optimizing Lambda: [-0.00986021299222462,7.27413172484976E17,2.2288334641864368E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10127 / 12293 = 0.8238
BLEU_precision(3) = 8613 / 11768 = 0.7319
BLEU_precision(4) = 7323 / 11244 = 0.6513
BLEU_precision = 0.7916
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7916

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
=> Optimizing Lambda: [-0.00986021299222462,7.27413172484976E17,2.2288334641864368E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10127 / 12293 = 0.8238
BLEU_precision(3) = 8613 / 11768 = 0.7319
BLEU_precision(4) = 7323 / 11244 = 0.6513
BLEU_precision = 0.7916
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7916

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
=> Optimizing Lambda: [-0.6541450753703264,2.8545816904647444E14,3.7796424090827615E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10236 / 12293 = 0.8327
BLEU_precision(3) = 8775 / 11768 = 0.7457
BLEU_precision(4) = 7512 / 11244 = 0.6681
BLEU_precision = 0.8025
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8025

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
=> Optimizing Lambda: [-1562.2322623758394,4.9088026535565776E16,-4.624065047234116]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9227 / 12293 = 0.7506
BLEU_precision(3) = 7213 / 11768 = 0.6129
BLEU_precision(4) = 5523 / 11244 = 0.4912
BLEU_precision = 0.6895
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.6895

 
	========================================================
train:20 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.05833333333333313,1.0269728137952615E8,1.8452841196372424E12]
test:10 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 146 / 146 = 1.0000
BLEU_precision(2) = 108 / 136 = 0.7941
BLEU_precision(3) = 87 / 126 = 0.6905
BLEU_precision(4) = 69 / 116 = 0.5948
BLEU_precision = 0.7557
Length of candidate corpus = 146
Effective length of reference corpus = 146
BLEU_BP = 1.0000
  => BLEU = 0.7557

 
	========================================================
train:20 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.04157087836698567,3928384.7705485113,6.658414057524934E10]
test:10 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 146 / 146 = 1.0000
BLEU_precision(2) = 111 / 136 = 0.8162
BLEU_precision(3) = 93 / 126 = 0.7381
BLEU_precision(4) = 78 / 116 = 0.6724
BLEU_precision = 0.7978
Length of candidate corpus = 146
Effective length of reference corpus = 146
BLEU_BP = 1.0000
  => BLEU = 0.7978

 
	========================================================
train:20 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.68
=> Optimizing Lambda: [-2.1439711198072344,-121857.43924850518,-0.028243239438093603]
test:10 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 146 / 146 = 1.0000
BLEU_precision(2) = 100 / 136 = 0.7353
BLEU_precision(3) = 76 / 126 = 0.6032
BLEU_precision(4) = 55 / 116 = 0.4741
BLEU_precision = 0.6772
Length of candidate corpus = 146
Effective length of reference corpus = 146
BLEU_BP = 1.0000
  => BLEU = 0.6772

 
	========================================================
train:20 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.05833333333333313,1.0269728137952615E8,1.8452841196372424E12]
test:10 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 146 / 146 = 1.0000
BLEU_precision(2) = 108 / 136 = 0.7941
BLEU_precision(3) = 87 / 126 = 0.6905
BLEU_precision(4) = 69 / 116 = 0.5948
BLEU_precision = 0.7557
Length of candidate corpus = 146
Effective length of reference corpus = 146
BLEU_BP = 1.0000
  => BLEU = 0.7557

 
	========================================================
train:20 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.058333333225435276,3928384.7705485113,6.658414057524934E10]
test:10 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 146 / 146 = 1.0000
BLEU_precision(2) = 111 / 136 = 0.8162
BLEU_precision(3) = 93 / 126 = 0.7381
BLEU_precision(4) = 78 / 116 = 0.6724
BLEU_precision = 0.7978
Length of candidate corpus = 146
Effective length of reference corpus = 146
BLEU_BP = 1.0000
  => BLEU = 0.7978

 
	========================================================
train:20 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.68
=> Optimizing Lambda: [-2.1439711198072344,-121857.43924850518,-0.04492943922115955]
test:10 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 146 / 146 = 1.0000
BLEU_precision(2) = 100 / 136 = 0.7353
BLEU_precision(3) = 76 / 126 = 0.6032
BLEU_precision(4) = 55 / 116 = 0.4741
BLEU_precision = 0.6772
Length of candidate corpus = 146
Effective length of reference corpus = 146
BLEU_BP = 1.0000
  => BLEU = 0.6772

 
	========================================================
train:20 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.05833333333333313,1.0269728137952615E8,1.8452841196372424E12]
test:10 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 146 / 146 = 1.0000
BLEU_precision(2) = 108 / 136 = 0.7941
BLEU_precision(3) = 87 / 126 = 0.6905
BLEU_precision(4) = 69 / 116 = 0.5948
BLEU_precision = 0.7557
Length of candidate corpus = 146
Effective length of reference corpus = 146
BLEU_BP = 1.0000
  => BLEU = 0.7557

 
	========================================================
train:20 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.058333333225435276,3928384.7705485113,6.658414057524934E10]
test:10 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 146 / 146 = 1.0000
BLEU_precision(2) = 111 / 136 = 0.8162
BLEU_precision(3) = 93 / 126 = 0.7381
BLEU_precision(4) = 78 / 116 = 0.6724
BLEU_precision = 0.7978
Length of candidate corpus = 146
Effective length of reference corpus = 146
BLEU_BP = 1.0000
  => BLEU = 0.7978

 
	========================================================
train:20 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.68
=> Optimizing Lambda: [-7.6503833727100705,277.48735053002264,0.07656767362683481]
test:10 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 146 / 146 = 1.0000
BLEU_precision(2) = 94 / 136 = 0.6912
BLEU_precision(3) = 69 / 126 = 0.5476
BLEU_precision(4) = 47 / 116 = 0.4052
BLEU_precision = 0.6258
Length of candidate corpus = 146
Effective length of reference corpus = 146
BLEU_BP = 1.0000
  => BLEU = 0.6258

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.027034017423342754,1.3781151528452435E15,2.294055266540741E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10433 / 12293 = 0.8487
BLEU_precision(3) = 8969 / 11768 = 0.7622
BLEU_precision(4) = 7705 / 11244 = 0.6853
BLEU_precision = 0.8159
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8159

 
	========================================================
train:500 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.027034017423342754,1.3781151528452435E15,2.294055266540741E15]
test:840 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 19469 / 19469 = 1.0000
BLEU_precision(2) = 15726 / 18629 = 0.8442
BLEU_precision(3) = 13398 / 17790 = 0.7531
BLEU_precision(4) = 11402 / 16954 = 0.6725
BLEU_precision = 0.8086
Length of candidate corpus = 19469
Effective length of reference corpus = 19469
BLEU_BP = 1.0000
  => BLEU = 0.8086

 
	========================================================
train:500 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.10634238705240086,2.0009103630428118E12,1.9454333883344635E15]
test:840 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 19469 / 19469 = 1.0000
BLEU_precision(2) = 15717 / 18629 = 0.8437
BLEU_precision(3) = 13454 / 17790 = 0.7563
BLEU_precision(4) = 11473 / 16954 = 0.6767
BLEU_precision = 0.8106
Length of candidate corpus = 19469
Effective length of reference corpus = 19469
BLEU_BP = 1.0000
  => BLEU = 0.8106

 
	========================================================
train:500 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.09216509025179964,-5603.7100178219935,0.1865907287992612]
test:840 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 19469 / 19469 = 1.0000
BLEU_precision(2) = 13703 / 18629 = 0.7356
BLEU_precision(3) = 10395 / 17790 = 0.5843
BLEU_precision(4) = 7684 / 16954 = 0.4532
BLEU_precision = 0.6644
Length of candidate corpus = 19469
Effective length of reference corpus = 19469
BLEU_BP = 1.0000
  => BLEU = 0.6644

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.027034017423342754,1.3781151528452435E15,2.294055266540741E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10433 / 12293 = 0.8487
BLEU_precision(3) = 8969 / 11768 = 0.7622
BLEU_precision(4) = 7705 / 11244 = 0.6853
BLEU_precision = 0.8159
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8159

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.10634238705240086,2.0009103630428118E12,1.9454333883344635E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10455 / 12293 = 0.8505
BLEU_precision(3) = 9036 / 11768 = 0.7678
BLEU_precision(4) = 7793 / 11244 = 0.6931
BLEU_precision = 0.8202
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8202

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.09216509025179964,-5603.7100178219935,0.1865907287992612]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9152 / 12293 = 0.7445
BLEU_precision(3) = 7038 / 11768 = 0.5981
BLEU_precision(4) = 5298 / 11244 = 0.4712
BLEU_precision = 0.6768
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.6768

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.089310397868531,2.5544387847821543E12,4.329928211728505E15]
test:807 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 18890 / 18890 = 1.0000
BLEU_precision(2) = 15163 / 18083 = 0.8385
BLEU_precision(3) = 12895 / 17277 = 0.7464
BLEU_precision(4) = 10946 / 16473 = 0.6645
BLEU_precision = 0.8030
Length of candidate corpus = 18890
Effective length of reference corpus = 18890
BLEU_BP = 1.0000
  => BLEU = 0.8030

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.05737837673665225,1.2308323540496023E14,8.663440353323336E14]
test:807 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 18890 / 18890 = 1.0000
BLEU_precision(2) = 15134 / 18083 = 0.8369
BLEU_precision(3) = 12847 / 17277 = 0.7436
BLEU_precision(4) = 10884 / 16473 = 0.6607
BLEU_precision = 0.8008
Length of candidate corpus = 18890
Effective length of reference corpus = 18890
BLEU_BP = 1.0000
  => BLEU = 0.8008

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.07012689304315362,1.92357979585956E12,2.5491746876125005E15]
test:807 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 18890 / 18890 = 1.0000
BLEU_precision(2) = 15269 / 18083 = 0.8444
BLEU_precision(3) = 13087 / 17277 = 0.7575
BLEU_precision(4) = 11179 / 16473 = 0.6786
BLEU_precision = 0.8117
Length of candidate corpus = 18890
Effective length of reference corpus = 18890
BLEU_BP = 1.0000
  => BLEU = 0.8117

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.1306696403802074,432469.59025679,-0.2915414993549898]
test:807 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 18890 / 18890 = 1.0000
BLEU_precision(2) = 13130 / 18083 = 0.7261
BLEU_precision(3) = 9805 / 17277 = 0.5675
BLEU_precision(4) = 7101 / 16473 = 0.4311
BLEU_precision = 0.6492
Length of candidate corpus = 18890
Effective length of reference corpus = 18890
BLEU_BP = 1.0000
  => BLEU = 0.6492

 
	========================================================
train:313 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.11852396885244931,3.355179610048263E14,4.5011205966216406E14]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 13690 / 13690 = 1.0000
BLEU_precision(2) = 11014 / 13164 = 0.8367
BLEU_precision(3) = 9396 / 12638 = 0.7435
BLEU_precision(4) = 7999 / 12113 = 0.6604
BLEU_precision = 0.8006
Length of candidate corpus = 13690
Effective length of reference corpus = 13690
BLEU_BP = 1.0000
  => BLEU = 0.8006

 
	========================================================
train:313 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.03396242505419221,9.94186179208302E12,7.977799109025406E14]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 13690 / 13690 = 1.0000
BLEU_precision(2) = 11143 / 13164 = 0.8465
BLEU_precision(3) = 9614 / 12638 = 0.7607
BLEU_precision(4) = 8271 / 12113 = 0.6828
BLEU_precision = 0.8143
Length of candidate corpus = 13690
Effective length of reference corpus = 13690
BLEU_BP = 1.0000
  => BLEU = 0.8143

 
	========================================================
train:313 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.10669235707306957,-13785.61832069162,-0.14813469595180176]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 13690 / 13690 = 1.0000
BLEU_precision(2) = 10030 / 13164 = 0.7619
BLEU_precision(3) = 7892 / 12638 = 0.6245
BLEU_precision(4) = 6114 / 12113 = 0.5047
BLEU_precision = 0.7000
Length of candidate corpus = 13690
Effective length of reference corpus = 13690
BLEU_BP = 1.0000
  => BLEU = 0.7000

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.75
=> Optimizing Lambda: [0.12706887154182633,4.513755690912956E14,3.7863069915638705E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10478 / 12293 = 0.8524
BLEU_precision(3) = 8991 / 11768 = 0.7640
BLEU_precision(4) = 7704 / 11244 = 0.6852
BLEU_precision = 0.8173
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8173

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.75
=> Optimizing Lambda: [0.10009934854908539,2.0009103630428513E12,1.945506862660054E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10562 / 12293 = 0.8592
BLEU_precision(3) = 9131 / 11768 = 0.7759
BLEU_precision(4) = 7878 / 11244 = 0.7006
BLEU_precision = 0.8267
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8267

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.75
=> Optimizing Lambda: [0.6491144004527248,-8310.03742442578,-0.18780324058604295]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9362 / 12293 = 0.7616
BLEU_precision(3) = 7289 / 11768 = 0.6194
BLEU_precision(4) = 5574 / 11244 = 0.4957
BLEU_precision = 0.6954
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.6954

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.8
=> Optimizing Lambda: [0.12706887154182633,4.513755690912956E14,3.7863069915638705E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10478 / 12293 = 0.8524
BLEU_precision(3) = 8991 / 11768 = 0.7640
BLEU_precision(4) = 7704 / 11244 = 0.6852
BLEU_precision = 0.8173
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8173

 
MAX========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.8
=> Optimizing Lambda: [0.10009934854908539,2.0009103630428513E12,1.945506862660054E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10562 / 12293 = 0.8592
BLEU_precision(3) = 9131 / 11768 = 0.7759
BLEU_precision(4) = 7878 / 11244 = 0.7006
BLEU_precision = 0.8267
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8267

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.8
=> Optimizing Lambda: [0.648708846356208,-8254.27072852004,-0.1835835803418677]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9362 / 12293 = 0.7616
BLEU_precision(3) = 7289 / 11768 = 0.6194
BLEU_precision(4) = 5574 / 11244 = 0.4957
BLEU_precision = 0.6954
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.6954

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.9
=> Optimizing Lambda: [0.16532383605976914,2.0347150181513515E15,3.2364827997598635E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9428 / 12293 = 0.7669
BLEU_precision(3) = 7290 / 11768 = 0.6195
BLEU_precision(4) = 5516 / 11244 = 0.4906
BLEU_precision = 0.6948
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.6948

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.9
=> Optimizing Lambda: [0.11159072132232276,5.029526686475321E13,2.22354981746298E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9477 / 12293 = 0.7709
BLEU_precision(3) = 7366 / 11768 = 0.6259
BLEU_precision(4) = 5602 / 11244 = 0.4982
BLEU_precision = 0.7002
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7002

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.027034017423342754,1.3781151528452435E15,2.16922622796959E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10431 / 12293 = 0.8485
BLEU_precision(3) = 8966 / 11768 = 0.7619
BLEU_precision(4) = 7701 / 11244 = 0.6849
BLEU_precision = 0.8157
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8157

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.10634238705240086,2.0009103630428118E12,1.9454333883344635E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10454 / 12293 = 0.8504
BLEU_precision(3) = 9035 / 11768 = 0.7678
BLEU_precision(4) = 7791 / 11244 = 0.6929
BLEU_precision = 0.8201
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8201

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.13304805362235392,-4277.99232306145,0.020745416904829988]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9162 / 12293 = 0.7453
BLEU_precision(3) = 7053 / 11768 = 0.5993
BLEU_precision(4) = 5314 / 11244 = 0.4726
BLEU_precision = 0.6778
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.6778

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [-0.00986021299222462,7.27413172484976E17,2.2288334641864368E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10126 / 12293 = 0.8237
BLEU_precision(3) = 8611 / 11768 = 0.7317
BLEU_precision(4) = 7320 / 11244 = 0.6510
BLEU_precision = 0.7915
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7915

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [-0.17712999050582473,2.854581690464744E14,1.3111687734407232E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10234 / 12293 = 0.8325
BLEU_precision(3) = 8774 / 11768 = 0.7456
BLEU_precision(4) = 7514 / 11244 = 0.6683
BLEU_precision = 0.8025
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8025

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [-0.00986021299222462,7.27413172484976E17,2.2288334641864368E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10126 / 12293 = 0.8237
BLEU_precision(3) = 8611 / 11768 = 0.7317
BLEU_precision(4) = 7320 / 11244 = 0.6510
BLEU_precision = 0.7915
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7915

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [-0.17712999050582473,2.854581690464744E14,1.3111687734407232E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10234 / 12293 = 0.8325
BLEU_precision(3) = 8774 / 11768 = 0.7456
BLEU_precision(4) = 7514 / 11244 = 0.6683
BLEU_precision = 0.8025
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8025

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,2.7253109831386456E14]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10420 / 12293 = 0.8476
BLEU_precision(3) = 9005 / 11768 = 0.7652
BLEU_precision(4) = 7774 / 11244 = 0.6914
BLEU_precision = 0.8183
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8183

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.04975277907319677,0.2,6.915585479814105E13]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10503 / 12293 = 0.8544
BLEU_precision(3) = 9154 / 11768 = 0.7779
BLEU_precision(4) = 7957 / 11244 = 0.7077
BLEU_precision = 0.8281
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8281

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.584560089096255,-0.1]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9351 / 12293 = 0.7607
BLEU_precision(3) = 7360 / 11768 = 0.6254
BLEU_precision(4) = 5707 / 11244 = 0.5076
BLEU_precision = 0.7010
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7010

 
	========================================================
